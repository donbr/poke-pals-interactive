# ğŸ“ PokÃ©Pals â€” Unified Architecture Tour for Students

*â€œFrom Button Click â†’ AI â†’ Tools â†’ Responseâ€*

This is the official **guided walkthrough** of how the PokÃ©Pals AI-powered web app works from end to end.
It is structured into **7 tour stops**, each one answering a single, critical question.

---

# ğŸ§­ **Tour Stop 1 â€” The Big Picture (Global Data Journey)**

**Question:** *What actually happens when a user interacts with the PokÃ©Pals app?*

```
User (Browser)
   â†“
UI Components (Next.js / React)
   â†“
API Route (/api/llm/*)
   â†“
Safety Pipeline (filters + system prompt)
   â†“
LLM Orchestrator (GPT-5-nano)
   â†“
Tool Execution (search, quiz, story, hints)
   â†“
External Services (OpenAI, PokeAPI)
   â†“
Return Value â†’ Streamed or JSON â†’ UI Update
```

**Student takeaway:**
You now know the **top-level shape** of the entire application.

---

# ğŸ¨ **Tour Stop 2 â€” The Presentation Layer**

**Question:** *How does the UI interact with the backend?*

The UI is built using:

* Next.js pages (server)
* Client components (interactive UI)
* Feature components (e.g., chat box, quiz, explorer)
* Tailwind + components for styling

ğŸ‘‰ *The UI never holds API keys.*
ğŸ‘‰ *The UI only talks to the server via safe endpoints.*

**Why this matters:**
It enforces **security** and teaches you how production systems handle sensitive operations.

---

# ğŸ—ï¸ **Tour Stop 3 â€” Business Logic Layer (The Server)**

**Question:** *Where do AI calls happen?*

On the server.

* Each endpoint (`/api/llm/chat`, `/story`, `/quiz`, `/search`, etc.) performs:

  * Input parsing
  * Validation (via Zod schemas)
  * Safety guards
  * OpenAI SDK calls
  * Tool logic when needed

This is where the AI is orchestrated.

**Student takeaway:**
Server endpoints act as the â€œcontrollerâ€ between UI and AI.

---

# ğŸ” **Tour Stop 4 â€” The Safety Pipeline**

**Question:** *How do we prevent unsafe prompts from reaching the LLM?*

Your code implements a **Safety Pipeline**:

```
User Input
   â†“
Regex Pre-Filter (blocks disallowed phrases)
   â†“
If Blocked â†’ Friendly Safe Response
   â†“
If Allowed â†’ System Prompt Injection
   â†“
OpenAI â†’ Streaming or JSON
```

This maps exactly to your real `chat/route.ts`.

**Student takeaway:**
Every production-quality AI app needs a **safety chain** before LLM inference.

---

# ğŸ§  **Tour Stop 5 â€” Agentic Thinking & Orchestrator Logic**

**Question:** *How does the LLM decide what to do?*

The Orchestrator LLM behaves like the â€œbrainâ€:

### **Generator Mode**

Used for:

* Chat
* Stories
* Quiz creation

The LLM **creates** content.

### **Router Mode**

Used for:

* PokÃ©mon search
* Type filtering
* Hint generation

The LLM **decides which tool to call**.

---

# ğŸŒ³ **Tour Stop 6 â€” Decision Tree (How AI Decides)**

**Question:** *How does the system choose the right behavior for the user request?*

```
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Chat? â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Chat Tool
User Message â”€â”€â”€â”€â”¤
                 â”œâ”€â”€â”€â”€ Story-like? â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Story Tool
                 â”‚
                 â”œâ”€â”€â”€â”€ Search intent? â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Search Tool
                 â”‚
                 â”œâ”€â”€â”€â”€ Quiz request? â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Quiz Tool
                 â”‚
                 â””â”€â”€â”€â”€ Safety Problem? â”€â”€â”€â”€â”€â”€â”€â”€â†’ Safe Fallback
```

**What students learn:**
This is **exactly** how LangGraph routers work.
This architecture *prepares you* to learn agent frameworks later.

---

# ğŸ§© **Tour Stop 7 â€” Tool Contracts (LLM â†” Function Interface)**

**Question:** *How does the LLM pass structured data to tools?*

Tool calls follow a strict contract:

```
User Intent
   â†“
LLM Router
   â†“
Input Schema (Zod)
   â†“
Validation
   â†“
Tool Execution (API calls, logic)
   â†“
Output Object
   â†“
LLM â†’ Formatted Response to the User
```

**Concrete example:**

```
User: "Show me all small fire PokÃ©mon."

Router Output:
{
  "types": ["fire"],
  "size": "small"
}

Tool Execution:
searchPokemon({ types:["fire"], size:"small" })

LLM Rendered Output:
"Here are 3 small fire PokÃ©mon you might like..."
```

**Student takeaway:**
Tools allow LLMs to act as *controllers*, not just text generators.

---

# ğŸ“¦ **Bonus Stop â€” Memory Layer (Future)**

This app will later integrate:

* **Vector memory (RAG)**
* **Graph memory (world or relationship memory)**
* **Event Log (Durable Execution)**

Students learn how small apps evolve into **enterprise-grade agentic systems**.

---

# ğŸ§  **Instructor Mode (Optional Supplemental Notes)**

Here are additional bullet points instructors can share:

* This architecture maps directly to **OpenAI Subagents**, **Claude Skills**, and **LangGraph Node Pipelines**.
* The app demonstrates the **entire lifecycle** of AI requests.
* Students can modify **any layer independently** (UI, logic, tools, memory, safety).
* It's a perfect starter template for **AI apps, games, copilots, and learning tools**.
